{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from pyro.infer import MCMC, NUTS, HMC\n",
    "from pyro.infer.mcmc.util import initialize_model, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(num_predictors, num_samples):\n",
    "    \"\"\"Generates samples from a simple poisson lognormal model (without noise)\"\"\"\n",
    "    #TODO: Add noise\n",
    "    betas = pyro.sample('betas', dist.Normal(torch.zeros(num_predictors+1), 0.25 * torch.ones(num_predictors+1)))\n",
    "    \n",
    "    with pyro.plate('gen_data_plate', num_samples):\n",
    "        with pyro.plate('gen_predictors_plate', num_predictors) as ind:\n",
    "            pred = pyro.sample('gen_predictors', dist.Uniform(0, 5))\n",
    "            X = torch.cat((torch.ones(1, num_samples), pred), 0)\n",
    "            thetas = betas @ X\n",
    "        accidents = pyro.sample('gen_accidents', dist.Poisson(torch.exp(thetas)))\n",
    "    return betas, X, accidents\n",
    "\n",
    "def prelim_model(num_predictors, num_observations, predictors, data):\n",
    "    \"\"\"Specifies the prior for a simple poisson lognormal model (without noise)\"\"\"\n",
    "    #TODO: Add noise\n",
    "    betas = pyro.sample('betas', dist.Normal(torch.zeros(num_predictors+1), 10 * torch.ones(num_predictors+1)))\n",
    "    thetas = betas @ predictors\n",
    "    with pyro.plate('observation_plate', num_observations):\n",
    "        accidents = pyro.sample('accidents', dist.Poisson(torch.exp(thetas)), obs=data)\n",
    "    return accidents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "num_predictors = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|          | 0/2000 [00:00, ?it/s]/home/asifmallik/.local/lib/python3.8/site-packages/pyro/poutine/subsample_messenger.py:58: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  result = torch.tensor(0., device=self.device)\n",
      "Sample: 100%|██████████| 2000/2000 [02:07, 15.64it/s, step size=1.22e-01, acc. prob=0.935]\n"
     ]
    }
   ],
   "source": [
    "betas, X, obs = generate(num_predictors, num_observations)\n",
    "nuts_kernel = NUTS(prelim_model, jit_compile=True)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=1000, num_chains=1, mp_context = \"spawn\")\n",
    "posterior = mcmc.run(num_predictors, num_observations, X, obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                mean       std    median      2.5%     97.5%     n_eff     r_hat\n",
      "  betas[0]      0.31      0.13      0.31      0.07      0.58    612.22      1.00\n",
      "  betas[1]     -0.34      0.02     -0.34     -0.38     -0.31   1283.14      1.00\n",
      "  betas[2]     -0.28      0.02     -0.28     -0.31     -0.25   1156.22      1.00\n",
      "  betas[3]     -0.12      0.01     -0.12     -0.15     -0.09   1301.30      1.00\n",
      "  betas[4]      0.38      0.02      0.38      0.35      0.41   1212.24      1.00\n",
      "  betas[5]     -0.03      0.01     -0.03     -0.06     -0.00   1458.41      1.00\n",
      "  betas[6]     -0.12      0.01     -0.12     -0.14     -0.08   1318.94      1.00\n",
      "  betas[7]     -0.23      0.02     -0.23     -0.25     -0.20   1564.98      1.00\n",
      "  betas[8]      0.27      0.02      0.27      0.24      0.30   1159.60      1.00\n",
      "  betas[9]     -0.13      0.02     -0.13     -0.16     -0.10   1232.97      1.00\n",
      " betas[10]      0.49      0.02      0.49      0.46      0.53   1632.94      1.00\n",
      "\n",
      "Number of divergences: 0\n",
      "tensor([ 0.2462, -0.3303, -0.2451, -0.1045,  0.3666, -0.0452, -0.1277, -0.2060,\n",
      "         0.2756, -0.1273,  0.4831])\n",
      "tensor([ 0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  2.,  2.,  0.,  0.,  2.,\n",
      "         0.,  1.,  0.,  0.,  3.,  0.,  0.,  2.,  1.,  0.,  2.,  0.,  1.,  2.,\n",
      "         1.,  0.,  3.,  2.,  2.,  0.,  0.,  3.,  0.,  1.,  8.,  0.,  1.,  1.,\n",
      "         8.,  1.,  0.,  1.,  1.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        11.,  0.,  5.,  2.,  0.,  0.,  0.,  3.,  2.,  0.,  3.,  0.,  2.,  2.,\n",
      "         0.,  1.,  0.,  1.,  0.,  1.,  2.,  0.,  0.,  0.,  1.,  2.,  7.,  0.,\n",
      "         1.,  4.,  2.,  8.,  0.,  7.,  1.,  0.,  3., 12.,  3.,  0.,  1.,  0.,\n",
      "         1.,  2.,  4.,  0.,  0.,  0.,  1.,  0.,  4.,  2.,  0.,  6.,  1., 12.,\n",
      "         0.,  0.,  1.,  2.,  2.,  1.,  1.,  7.,  7.,  2.,  3.,  0.,  1.,  6.,\n",
      "         1.,  1.,  2.,  0.,  1.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,\n",
      "         0.,  1.,  0.,  5.,  0.,  4.,  2.,  0.,  2.,  1.,  8.,  0.,  0.,  7.,\n",
      "         7.,  6.,  1.,  0.,  5.,  0.,  0.,  0.,  0.,  4.,  0.,  3.,  0.,  4.,\n",
      "         3.,  0.,  3.,  8.,  0.,  2.,  0.,  4., 16.,  2., 12.,  1.,  1.,  0.,\n",
      "         6.,  9.,  1.,  0.,  2.,  1.,  1.,  1.,  2.,  1.,  2., 13.,  0.,  0.,\n",
      "         4.,  1.,  0.,  0.,  6.,  1., 11.,  0.,  2.,  6.,  1.,  4.,  0.,  0.,\n",
      "         0.,  0.,  2.,  0.,  1., 11.,  0.,  0.,  2.,  0.,  1.,  7.,  3.,  0.,\n",
      "         0.,  0.,  8., 15.,  1.,  3.,  2.,  1.,  2.,  4.,  3.,  4.,  0.,  0.,\n",
      "         7., 11.,  3.,  0.,  8.,  2.,  3.,  5.,  4.,  0.,  3.,  1.,  3.,  0.,\n",
      "         3., 10.,  2.,  2.,  3.,  2.,  0.,  1.,  0.,  0.,  8.,  0., 11.,  2.,\n",
      "         4.,  2.,  1.,  9.,  1.,  0.,  1.,  2.,  5.,  5.,  4.,  0.,  1.,  0.,\n",
      "         0.,  0.,  2.,  5.,  5.,  1.,  3.,  2.,  5.,  4.,  2.,  1.,  2.,  2.,\n",
      "         1.,  9.,  2.,  5.,  0.,  1.,  3.,  0.,  0.,  0.,  0.,  1., 10.,  0.,\n",
      "         7.,  0.,  1.,  3.,  0.,  0.,  2.,  0.,  1.,  3.,  1.,  2., 14.,  2.,\n",
      "         1.,  2.,  2.,  0.,  1.,  1.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  5.,  1.,  0.,  2.,  0.,  1.,  6.,  2., 10.,  3.,  0.,  0.,  0.,\n",
      "        17.,  9.,  4.,  2.,  0.,  0.,  0.,  1.,  0.,  7.,  0.,  0.,  4.,  0.,\n",
      "         2.,  0.,  0.,  0.,  4.,  0.,  2.,  1.,  0.,  0.,  0.,  0., 11.,  4.,\n",
      "         0.,  3., 12.,  1.,  0.,  1.,  0.,  0.,  2.,  0.,  3.,  7.,  5.,  0.,\n",
      "         2.,  1.,  1., 22., 22.,  3.,  0.,  4.,  1.,  0.,  0.,  4.,  3.,  1.,\n",
      "         1.,  1.,  0.,  0.,  0.,  1.,  3.,  0.,  0.,  0.,  2.,  2., 10.,  0.,\n",
      "         0.,  1.,  0.,  7.,  2.,  1.,  0.,  3.,  8.,  2.,  0.,  6.,  3.,  2.,\n",
      "         6.,  0.,  1.,  1.,  3.,  0.,  0.,  0.,  1.,  1.,  0.,  3.,  1.,  7.,\n",
      "         0.,  2.,  0., 12.,  4.,  0.,  1.,  1.,  0.,  2.,  2.,  2.,  0.,  0.,\n",
      "         0.,  0.,  1.,  2.,  0.,  0.,  0.,  2.,  1.,  3.,  0.,  1.,  0.,  2.,\n",
      "         0.,  0.,  2.,  1.,  0.,  1.,  3.,  2.,  3.,  2.,  0.,  0.,  1.,  1.,\n",
      "         3., 17.,  0.,  0.,  8.,  1.,  0.,  1.,  2.,  1.,  1.,  2.,  1.,  2.,\n",
      "         0.,  2.,  5.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  2.,  3.,  1.,\n",
      "         2.,  1.,  0.,  3.,  2.,  0.,  2.,  0.,  2.,  3.,  1.,  0.,  1.,  9.,\n",
      "         2.,  3.,  0.,  0.,  0.,  5.,  2.,  0.,  2.,  2.,  2.,  4.,  1.,  0.,\n",
      "         0.,  0.,  1.,  1.,  2.,  7.,  0.,  1.,  2.,  2.,  1.,  1.,  0.,  1.,\n",
      "         3.,  0.,  0.,  4.,  1.,  0.,  5.,  3.,  2.,  0.,  0.,  0., 15.,  3.,\n",
      "         1.,  0.,  2.,  2.,  1.,  1.,  1.,  2.,  6.,  3.,  1.,  3.,  5., 17.,\n",
      "         2.,  0.,  0.,  0.,  2.,  0.,  0.,  0., 12.,  2.,  2.,  0.,  0.,  0.,\n",
      "         1.,  0.,  3.,  4.,  3.,  5.,  9.,  0.,  0.,  0., 10.,  0.,  3.,  1.,\n",
      "         6.,  1.,  0.,  2.,  3.,  0.,  1.,  0.,  2.,  3.,  0.,  7.,  5.,  0.,\n",
      "         9.,  0.,  2.,  2.,  4.,  1.,  1.,  0.,  1.,  4.,  1.,  2.,  1.,  3.,\n",
      "         0.,  4.,  0.,  2.,  2.,  0.,  5.,  4.,  0.,  0.,  0.,  0.,  0., 20.,\n",
      "         3.,  1.,  2.,  3.,  0.,  3.,  0.,  0.,  0., 27.,  3.,  1.,  0.,  4.,\n",
      "         0.,  2.,  0.,  2.,  0.,  1.,  6.,  0.,  1.,  0.,  0.,  6.,  2.,  5.,\n",
      "         0.,  4.,  0.,  2.,  0.,  0.,  6.,  0.,  7.,  1.,  9.,  7.,  0.,  1.,\n",
      "         0.,  0.,  1., 15.,  0.,  2.,  1.,  1.,  5.,  8.,  2.,  0.,  0.,  1.,\n",
      "        38.,  0.,  4.,  5.,  0.,  0.,  0.,  2.,  1.,  1.,  2.,  6.,  2.,  0.,\n",
      "         1.,  0.,  3.,  0.,  1.,  5.,  0.,  1.,  1.,  0.,  0.,  1., 18.,  0.,\n",
      "         3., 20.,  2.,  0.,  0.,  3.,  0.,  2.,  0.,  0.,  3.,  0.,  0.,  0.,\n",
      "         1.,  2.,  0.,  5.,  0.,  1.,  2.,  0.,  1.,  1.,  1.,  2.,  0.,  1.,\n",
      "         1.,  1.,  0.,  0.,  4.,  1.,  3.,  5.,  0., 13.,  0.,  1.,  2.,  0.,\n",
      "         6.,  6.,  1.,  5.,  0.,  0.,  1.,  1.,  2., 16.,  1.,  1.,  4., 20.,\n",
      "         1.,  0.,  2.,  0.,  7.,  0.,  0.,  1.,  0.,  3.,  5.,  1.,  3.,  1.,\n",
      "         0.,  1., 12.,  2.,  1., 12.,  0.,  0.,  2.,  0.,  0.,  7.,  0.,  0.,\n",
      "         1.,  1.,  0.,  0.,  2.,  0.,  5.,  2.,  5.,  1.,  0.,  0.,  3.,  3.,\n",
      "         4.,  0.,  0.,  0.,  0.,  0.,  0.,  6.,  2.,  1.,  0.,  1.,  0.,  2.,\n",
      "         0.,  0.,  0.,  0.,  0.,  2.,  0.,  1.,  0.,  0.,  0.,  0.,  7.,  0.,\n",
      "         2.,  1.,  3.,  1.,  4.,  2.,  0., 15.,  5.,  0.,  1.,  1.,  3.,  1.,\n",
      "         2.,  1.,  1.,  7.,  0.,  3.,  4.,  6.,  1.,  1.,  7.,  0.,  1.,  4.,\n",
      "         9.,  0.,  0.,  0.,  7.,  1.,  4.,  5.,  4.,  1.,  0., 13.,  0.,  1.,\n",
      "        11., 16.,  0.,  1.,  0., 10.,  0.,  0.,  1.,  0., 43.,  0., 10.,  1.,\n",
      "         0.,  0.,  1.,  2.,  0.,  4.,  1.,  3.,  3.,  5.,  1.,  4.,  1.,  1.,\n",
      "         0.,  4., 16.,  0.,  3.,  5.,  0.,  1.,  3.,  4., 10.,  0.,  1.,  2.,\n",
      "         1.,  0.,  1.,  3.,  3.,  0.,  8.,  0.,  3.,  1.,  4.,  2.,  1.,  0.,\n",
      "         0.,  0.,  7.,  1.,  1.,  0.,  0.,  0.,  2.,  6.,  2.,  2.,  1.,  1.,\n",
      "         0.,  5.,  0.,  0.,  3.,  3.,  1.,  4.,  3.,  3.,  3.,  4.,  3.,  0.,\n",
      "         1.,  3.,  0.,  2.,  1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "mcmc.summary(prob=0.95)\n",
    "print(betas)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
