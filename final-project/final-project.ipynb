{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from helper_functions import ppc\n",
    "from models import models, guides\n",
    "from plots import plots \n",
    "import predictors\n",
    "from models import posterior\n",
    "import pyro.contrib.autoguide as autoguide\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "import data\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Crash Prediction in Manhattan using Variational Inference\n",
    "\n",
    "Over 1.73 million crash incidents have been reported in NYC since 2012. The magnitude of this number indicates the importance of developing and understanding of the patterns that drive this phenomenon. With the aim of achieving this objective we developed various probability models that describe how the phenomenon occurs on a day to day level in different regions within Manhattan. We perform inference on our model using Stochastic Variational inference.\n",
    "## Data description\n",
    "We used four types of data. \n",
    "1. Location and time of all car crashes reported in Manhattan from [NYC OpenData](https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95)\n",
    "\n",
    "2. Daily average temperature, wind speed, rain volume and snow depth at JFK airport collected from [NCDC](https://www.ncdc.noaa.gov/cdo-web/search)\n",
    "\n",
    "3. Intersection location and characteristics for all intersection of manhattan from [Kaggle](https://www.kaggle.com/crailtap/street-network-of-new-york-in-graphml)\n",
    "\n",
    "4. Annual average daily traffic for all road segments in manhattan for which this information was available, taken from [NY government](https://data.ny.gov/Transportation/Annual-Average-Daily-Traffic-AADT-Beginning-1977/6amx-2pbv) \n",
    "\n",
    "\n",
    "Below we plot some graphs that show different aspects of our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents, preds  = data.get_data()\n",
    "plots.make_heat_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.make_mean_log_mean(accidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below plots accidents through time and uses a smoother to detect trends through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.make_time_series(accidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation\n",
    "To aggregate the data we decided to map each accident to the nearest intersection. We decided to use the average AADT over the period from 2014 to 2019 for each road as there was missing data. We matched the AADT of the roads to the intersections by proximity. Roads without AADT data available were remove. For interpretability and inference purposes we used normalized $\\log$(AADT).\n",
    "\n",
    "## Model definition\n",
    "The main model that we used is a poisson log-normal model. Let $m$ denote the number of days, $n$ the number of sites or regions, and $k$ the number of predictors. Then we let  $Y_{ij} $ denote the number of car crashes in region $i$ on day $j$.  Call $\\beta \\in \\mathbb{R}^k$ the regression coefficients and $X_{ij} \\in \\mathbb{R}^k$ the predictors for site $i$ on day $k$. We then assume that the data is generated from the following model \n",
    "\n",
    "\n",
    "$$\\epsilon \\sim \\mathcal{N}(0, 10^2 * I_n)\\\\\n",
    "\\beta \\sim \\mathcal{N}(0, 5^2 * I_k)\\\\\n",
    "\\log(\\theta_{ij}) = X_{ij}^\\top \\beta + \\epsilon_{i}\\\\\n",
    "Y_{ij} \\sim \\text{Poisson}(\\theta_{ij})$$\n",
    "\n",
    "## Preliminary Investigations: Inference Method and Model Choices\n",
    "\n",
    "Before working on the real data, we implemented our main models and fit them to synthetically generated data from the model itself. We found that the models were able to recover the correct betaâ€™s even when the generated data had similar sparsity as the real data. We learned two things from this:\n",
    "\n",
    "- Initially, we were planning on fitting a conditional autoregressive model using spatial correlation. However, we found this to be prohibitively computationally expensive regardless of inference method due to computations involving large spatial matrices. Due to the large number of intersections, this was not a feasible model. As such, we decided to use the poisson-lognormal model.\n",
    "\n",
    "- Initially, we wanted to use MCMC as our inference method but we soon found this to be computationally infeasible due to the large amount of data. Instead, we choice to use stochastic variational inference using Pyro's automatic guide generation. \n",
    "\n",
    "- We note hencefoth that every inference was performed using a meanfield variational family of the same family of the prior. \n",
    "\n",
    "## Base model \n",
    "For our base model we assume that $k = 1$. This is equivalent to assuming no structure across nodes and simply modelling every region independently and an intercept. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_names = []\n",
    "kappa = 0.55\n",
    "t_0 = 20\n",
    "loss, guide = models.train_log_linear_random_init(accidents,\n",
    "                        preds,\n",
    "                        pred_names, \n",
    "                        kappa=kappa,\n",
    "                        t_0=t_0, \n",
    "                        max_iters=1000)\n",
    "plots.plot_svi_loss(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = predictors.get_some_predictors(preds, pred_names)\n",
    "predict = posterior.Predict(models.log_linear_model, guide, 300)\n",
    "samples = predict(accidents.shape[0], accidents.shape[1], selection.shape[2], torch.Tensor(selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPC \n",
    "\n",
    "We now check whether our model is able to generate similar data to the actual data. To do so, we conduct two posterior predictive checks:\n",
    "\n",
    "- The actual number of accidents at an intersection and the empirical distribution constructed from the posterior predictictive samples. We expect a good model to have the mean of the empirical distribution to coincide with the actual data.\n",
    "- The max number of accidents during one day at a given intersection during some period of time at the emprical distribution of this same quantity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.plot_total_distributions(samples['accidents'].detach().numpy(), accidents, (2,2), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.plot_max(samples['accidents'].detach().numpy(), accidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining the disparity with maximum\n",
    "As the plots above show, the maximum number of crashes at a particular site is not captured well. Thus, we decided to fit negative bionomial model as it allows for an excess kurtosis greater than that of a poisson. \n",
    "We modeled the mean with the same structure as our main model and used a uniform prior over the parameter $p$ (success probability in each trial). In particular $\\log(\\theta)$ is defined as before and $\\theta$ denotes mean of binomial but now we let $p_i \\sim \\text{Beta}(\\alpha_0, \\alpha_1)$. Both of these values parametrize the distribution. We choose here $\\alpha_0 = \\alpha_1 = 0$ and we assume that $Y_{ij}  \\sim \\text{Binom}(\\theta_{ij}, p_i).$ under this particular parameterization of the binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_days = 365\n",
    "selection = predictors.get_some_predictors(preds, [])[:,:num_days]\n",
    "kappa = 0.5 + 1e-10\n",
    "t_0 = 40\n",
    "model_args = {'num_sites':accidents.shape[0],\n",
    "             'num_days':num_days,\n",
    "              'num_predictors':selection.shape[-1], \n",
    "              'predictors': torch.Tensor(selection),\n",
    "             'data': torch.Tensor(accidents[:,:num_days])}\n",
    "\n",
    "losses = models.train(models.negative_binomial_log_linear_model,\n",
    "                      guides.negative_binomial_guide,\n",
    "                      kappa = kappa,\n",
    "                      t_0 = t_0,\n",
    "                      model_args = model_args,\n",
    "                      max_iters = 100\n",
    "                     )\n",
    "plots.plot_svi_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = posterior.Predict(models.negative_binomial_log_linear_model, guides.negative_binomial_guide, 400)\n",
    "binsamples = predict(accidents.shape[0], num_days, selection.shape[2], torch.Tensor(selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.plot_total_distributions(binsamples['accidents'].detach().numpy(),accidents[:,:num_days],(2,2),12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.plot_max(binsamples['accidents'].detach().numpy() ,accidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify whether these results made sense we decided to compare the variance to the mean across sites. We determined that they were a poor approximation to reality. Moreover, we found three outliers which accounter for days with more than six crashes. We decide against using a negative binomial model and choose poisson as it approximates data more accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_mean_variance_line(binsamples['accidents'].detach().numpy()[np.random.randint(0,400)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_mean_variance_line(accidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection Model \n",
    "The next step is to add local data to the nodes like AADT and whether the node is an intersection of 3 or more roads (as sometimes the node is simply a corner). After fitting the model, we see that the PPC sample has a similar empirical distribution of the mean difference as the actual data. Thus, this model is better able to capture node differeneces. However, we find it surprising that the AADT has a negative coefficient because intuitively we expected higher traffic to translate to greater accidents. Perhaps, this is due to higher traffic intersections having certain characteristics that make accidents less likely or AADT (as measured by us) capturing additional information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_names = ['aadt','is_intersection']\n",
    "kappa = 0.5\n",
    "t_0 = 20\n",
    "loss, guide = models.train_log_linear_random_init(accidents,\n",
    "                        preds,\n",
    "                        pred_names, \n",
    "                        kappa=kappa,\n",
    "                        t_0=t_0, \n",
    "                        max_iters=3000)\n",
    "plots.plot_svi_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = predictors.get_some_predictors(preds, pred_names)\n",
    "predict = posterior.Predict(models.log_linear_model, guide, 400)\n",
    "insamples = predict(accidents.shape[0], accidents.shape[1], selection.shape[2], torch.Tensor(selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_betas(insamples['betas'].detach().numpy(), pred_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional PPC\n",
    "We introduce two additional PPCs to our model: \n",
    "- We plot the quantiles from posterior predictive of the a svagol filtered plot of total car crashes in Manhattan per day against the same quantity observed in data. We use window of 61 and polynomial of 3. \n",
    "\n",
    "- We introduce a further check to test whether a given categorical daily predictor affects accident rates. Assume a histogram of the difference between the mean accident for each node across days when the categorical predictor is 1 and the corresponding mean when it is 0. If said predictor does indeed affect the accident rate, we expect the histogram to have non-zero mean and be skewed . We can conduct  a check  by plotting skewness  of the histogram described above calculated from posterior samples according to truth. This is done below. This strategy works generally. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.plot_time_trend(insamples['accidents'].detach().numpy(),accidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.plot_mean_difference(accidents,preds[:,0,2],0, title='Mean difference of is_intersection in real dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.plot_skew(insamples['accidents'], accidents,preds[:,0,2],0 ,title='Skewness of intersection mean differences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the skew plot is adequate but time not very much. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather-Intersection model \n",
    "\n",
    "This prompts us to add predictors related to the day. We add temperature, snow depth, wind and precipitation as predictors as these are natural factors that one would expect to affect accident rates. After fitting the model using SVI, we apply the above PPC again. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the second criteria is better captured by this model but not perfectly. Due to the non-stationary confidence interval implied by our modified model, it is better able to capture the time-trends in the aggregate data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_names = ['aadt','is_intersection', 'wind','snow_depth', 'temperature','precipitation']\n",
    "kappa = 0.55\n",
    "t_0 = 30\n",
    "loss, guide = models.train_log_linear_random_init(accidents,preds,pred_names,kappa=kappa,t_0=t_0,max_iters=2000)\n",
    "plots.plot_svi_loss(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = predictors.get_some_predictors(preds, pred_names)\n",
    "predict = posterior.Predict(models.log_linear_model, guide, 400)\n",
    "wsamples = predict(accidents.shape[0], accidents.shape[1], selection.shape[2], torch.Tensor(selection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc.plot_time_trend(wsamples['accidents'].detach().numpy(), accidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppc.plot_skew(wsamples['accidents'], accidents,preds[0,:,5] > 0,1 ,title='Skewness of mean differences Snow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous checked all yielded adequate results. Our betas obtained are the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plots.plot_betas(wsamples['betas'].detach().numpy(), pred_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We see that rain has a significant positive coefficient indicating that rain increases ratee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complication with SVI\n",
    "\n",
    "When fitting the above model we noticed that running inference multiple times led to inconsistent results from the PPC. Sometimes, the trend lines would fit well and other times it would not. After studying the corresponding ELBO curves, we concluded that this was due to the ELBO not converging even after a significant number of iterations (~5000 iterations). We found that this was due to bad initialization of the guide. To prevent this, we initialize the guide a hundred times and select the initialization based on the lowest ELBO. This led us to consistent results from the PPC. The PPCs were crucial for us to understand this result and although not explicitely mentioend here they were used to check inference and verify model convergence.  \n",
    "\n",
    "\n",
    "## Future Directions and Other attempts\n",
    "We noticed two things that prompted us to define a mixture model:\n",
    "We observed that for certain predictors, mean-field SVI parameters tended to converge to two or three different peaks. This may indicate that the posterior is multimodal and may reduce to unimodal when considering a single cluster assignment\n",
    "For certain predictors, the PPC for mean difference seems to have smaller peaks\n",
    "In the mixture model, we assign the nodes to several different sets of betas and the rest is identical to our main model. We define this model in models/models.py and we fit this using MAP showing heterogeneous results. However, we did not have enough time to properly fit and criticize the results of this model. So, we believe this to be an extremely promising future direction that we plan to look into."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
