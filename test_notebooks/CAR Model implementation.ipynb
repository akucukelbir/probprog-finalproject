{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will will create a model from which the data is produced. I assume that we have an $n \\times n$ grid of numbers and a period of $N$ days. The refernce for the model used can be found on https://mc-stan.org/users/documentation/case-studies/mbjoseph-CARStan.html ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import seaborn as sbn\n",
    "import pandas as pd\n",
    "import pyro \n",
    "import pyro.distributions as dist\n",
    "import numpy as np \n",
    "import torch\n",
    "from pyro.infer import MCMC, NUTS\n",
    "sys.path.append('../')\n",
    "\n",
    "from helper_functions import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specify the adjacency matrix used to generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.74737730e-01, 4.94754598e-02, 9.01151269e-03, ...,\n",
       "        3.06906769e-22, 9.06619310e-23, 4.53309655e-23],\n",
       "       [4.94754598e-02, 1.84798323e-01, 3.31074464e-02, ...,\n",
       "        5.51353598e-22, 1.70913872e-22, 9.06619310e-23],\n",
       "       [9.01151269e-03, 3.31074464e-02, 1.81794090e-01, ...,\n",
       "        1.70864476e-21, 5.51353598e-22, 3.06906769e-22],\n",
       "       ...,\n",
       "       [3.06906769e-22, 5.51353598e-22, 1.70864476e-21, ...,\n",
       "        1.81794090e-01, 3.31074464e-02, 9.01151269e-03],\n",
       "       [9.06619310e-23, 1.70913872e-22, 5.51353598e-22, ...,\n",
       "        3.31074464e-02, 1.84798323e-01, 4.94754598e-02],\n",
       "       [4.53309655e-23, 9.06619310e-23, 3.06906769e-22, ...,\n",
       "        9.01151269e-03, 4.94754598e-02, 2.74737730e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = 20\n",
    "cols = 20\n",
    "alpha = 0.5\n",
    "\n",
    "W = utils.make_grid_adjacency_matrix(rows, cols)\n",
    "D_inv = np.diag(1/np.sum(W, 1))\n",
    "D = np.diag(np.sum(W,1))\n",
    "B = D_inv @ W\n",
    "tau = 2\n",
    "alpha = 0.5\n",
    "prec_mat =  tau*D@(np.identity(rows * cols) - alpha * B)\n",
    "np.linalg.inv(prec_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## T\n",
    "rows = 15\n",
    "cols = 15\n",
    "num_predictors = 2\n",
    "var_beta = 1\n",
    "noise_var = 0.025\n",
    "def data_generation(rows, cols, num_predictors, var_beta, noise_var): \n",
    "    \"\"\" \n",
    "    row and col denote the rows and columns of the grid\n",
    "    num_predictors indicates how many betas are used in the \n",
    "    log normal poisson model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary to keep the parameters in store\n",
    "    params = {}\n",
    "    \n",
    "    n = rows * cols\n",
    "    \n",
    "    beta_dist = dist.Normal(torch.zeros(num_predictors + 1), var_beta)\n",
    "    betas = pyro.sample('betas',beta_dist)\n",
    "    params['betas'] = betas\n",
    "    \n",
    "    # Spatial correlation\n",
    "    W = torch.Tensor(utils.make_grid_adjacency_matrix(rows, cols))\n",
    "    D_inv = torch.diag(1/torch.sum(W,1))\n",
    "    D = torch.diag(torch.sum(W, 1))\n",
    "    B = D_inv @ W\n",
    "    alpha = pyro.sample('alpha', dist.Uniform(0,1))\n",
    "    tau = pyro.sample('tau', dist.Gamma(2,2))\n",
    "    prec_mat = tau * D @ (torch.eye(n) - alpha * B)\n",
    "    \n",
    "    params['alpha'] = alpha\n",
    "    params['tau'] = tau\n",
    "    \n",
    "    phi_dist = dist.MultivariateNormal(torch.zeros(n), precision_matrix = prec_mat)\n",
    "    phi = pyro.sample('phi', phi_dist)\n",
    "    params['phi'] = phi\n",
    "\n",
    "\n",
    "    with pyro.plate('gen_data_plate', rows * cols): \n",
    "        noise = pyro.sample('noise', dist.Normal(0,noise_var))\n",
    "        with pyro.plate('gen_predictor_plate', num_predictors):\n",
    "            predictors = pyro.sample('predictors', dist.Uniform(-1,1))\n",
    "            \n",
    "    ones = torch.unsqueeze(torch.ones(rows * cols), 0)\n",
    "    predictors = torch.cat((predictors, ones), 0)\n",
    "    params['predictors'] = predictors\n",
    "    log_theta =  predictors.T @ betas + noise + phi\n",
    "    theta = torch.exp(log_theta)\n",
    "    accidents = pyro.sample('accidents', dist.Poisson(theta))\n",
    "    params['accidents'] = accidents\n",
    "\n",
    "    return params\n",
    "    \n",
    "    \n",
    "    \n",
    "params = data_generation(rows,cols, num_predictors, var_beta, noise_var)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 225])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['predictors'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the plot below we do see that there seems to be some form of spatial correlation in that there are clusters of points with higher density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1121)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = np.reshape(params['accidents'].numpy(),(rows,cols))\n",
    "print(params['alpha'])\n",
    "sbn.heatmap(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.Tensor(utils.make_grid_adjacency_matrix(rows, cols))\n",
    "D_inv = torch.diag(1/torch.sum(W,1))\n",
    "D = torch.diag(torch.sum(W, 1))\n",
    "B = D_inv @ W\n",
    "def model(accidents, predictors):\n",
    "    n = rows * cols\n",
    "    \n",
    "    beta_dist = dist.Normal(torch.zeros(num_predictors + 1), var_beta)\n",
    "    betas = pyro.sample('betas',beta_dist)\n",
    "    \n",
    "    # Spatial correlation\n",
    "    alpha = pyro.sample('alpha', dist.Uniform(0.8,1))\n",
    "    tau = pyro.sample('tau', dist.Gamma(2,2))\n",
    "    prec_mat = tau * D @ (torch.eye(n) - alpha * B)\n",
    "\n",
    "    phi_dist = dist.MultivariateNormal(torch.zeros(n), precision_matrix = prec_mat)\n",
    "    phi = pyro.sample('phi', phi_dist)\n",
    "    \n",
    "    with pyro.plate('gen_data_plate', rows * cols): \n",
    "        noise = pyro.sample('noise', dist.Normal(0,noise_var))\n",
    "            \n",
    "    log_theta =  predictors @ betas + noise + phi\n",
    "    theta = torch.exp(log_theta)\n",
    "    pyro.sample('accidents', dist.Poisson(theta), obs = accidents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 11000/11000 [18:06, 10.12it/s, step size=2.67e-01, acc. prob=0.848]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(model, jit_compile=True, ignore_jit_warnings=True)\n",
    "mcmc = MCMC(nuts_kernel, num_samples = 10000, warmup_steps = 1000)\n",
    "mcmc.run(params['accidents'], params['predictors'].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: betas\n",
      "       mean       std        5%       25%       50%       75%       95%\n",
      "0 -0.192864  0.082753 -0.327374 -0.249098 -0.193866 -0.137244 -0.055506\n",
      "1 -1.351493  0.095334 -1.509377 -1.415434 -1.351204 -1.287573 -1.195462\n",
      "2  0.661061  0.094567  0.519320  0.610254  0.666484  0.719334  0.798773 \n",
      "\n",
      "site: alpha\n",
      "       mean      std        5%       25%       50%       75%       95%\n",
      "0  0.865907  0.04763  0.805121  0.825881  0.856999  0.898153  0.956343 \n",
      "\n",
      "site: tau\n",
      "       mean       std        5%       25%       50%       75%       95%\n",
      "0  2.983373  0.783185  1.905216  2.416387  2.877721  3.438708  4.437792 \n",
      "\n",
      "site: phi\n",
      "         mean       std        5%       25%       50%       75%       95%\n",
      "0    0.256603  0.278760 -0.209846  0.073857  0.257319  0.442840  0.707216\n",
      "1   -0.090121  0.285243 -0.564693 -0.277498 -0.086750  0.105755  0.362700\n",
      "2   -0.160901  0.375364 -0.774972 -0.413670 -0.159338  0.090220  0.448939\n",
      "3   -0.372223  0.342538 -0.944676 -0.596937 -0.365581 -0.140121  0.175798\n",
      "4   -0.258060  0.379952 -0.892600 -0.505020 -0.247835  0.000531  0.353042\n",
      "..        ...       ...       ...       ...       ...       ...       ...\n",
      "220  0.654058  0.325790  0.124718  0.430831  0.653674  0.871474  1.190893\n",
      "221  0.086543  0.357521 -0.507849 -0.149151  0.087141  0.327699  0.660773\n",
      "222  0.039475  0.355823 -0.543256 -0.199702  0.042072  0.276516  0.623731\n",
      "223  0.173072  0.335452 -0.377938 -0.050172  0.176616  0.391575  0.729516\n",
      "224  0.077352  0.444818 -0.661727 -0.214444  0.078426  0.371263  0.803467\n",
      "\n",
      "[225 rows x 7 columns] \n",
      "\n",
      "site: noise\n",
      "         mean       std        5%       25%       50%       75%       95%\n",
      "0    0.000703  0.025318 -0.040946 -0.016231  0.001022  0.017849  0.041658\n",
      "1   -0.000443  0.025117 -0.041795 -0.017373 -0.000602  0.016882  0.040724\n",
      "2    0.000187  0.024920 -0.041160 -0.016681  0.000529  0.016661  0.041069\n",
      "3   -0.001269  0.024408 -0.041091 -0.018031 -0.000990  0.015051  0.039176\n",
      "4    0.000212  0.024640 -0.040517 -0.016119  0.000435  0.016844  0.040151\n",
      "..        ...       ...       ...       ...       ...       ...       ...\n",
      "220  0.002160  0.025286 -0.039437 -0.015073  0.002478  0.019218  0.043723\n",
      "221 -0.000943  0.024951 -0.041796 -0.018063 -0.000950  0.015713  0.040508\n",
      "222 -0.000716  0.024889 -0.041475 -0.017328 -0.000933  0.016055  0.040678\n",
      "223  0.000534  0.024727 -0.040121 -0.016421  0.000456  0.017213  0.040811\n",
      "224 -0.000027  0.024911 -0.040759 -0.016845 -0.000189  0.016826  0.040831\n",
      "\n",
      "[225 rows x 7 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}\n",
    "\n",
    "for site, values in summary(hmc_samples).items():\n",
    "    print(\"site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas\n",
      "tensor([-0.2059, -1.3564,  0.6777])\n",
      "alpha\n",
      "tensor(0.1121)\n",
      "tau\n",
      "tensor(2.3142)\n",
      "phi\n",
      "tensor([ 0.5901, -0.3430,  0.1099, -0.6282, -0.0218,  0.3656,  0.4804, -0.5921,\n",
      "        -0.0581,  0.4385, -0.4251, -0.5162, -0.3288,  0.5274, -0.3447, -0.3570,\n",
      "         0.0088, -0.5025, -0.0061, -0.1532,  0.1138, -0.0172,  0.6078, -0.5307,\n",
      "        -0.1846, -0.1078, -0.0354,  0.0309,  0.2951, -0.4887, -0.0019,  0.6475,\n",
      "         0.1099, -0.1359, -0.7193, -0.2853,  0.5342,  0.7988,  0.0583, -0.2783,\n",
      "         0.2530, -0.6635, -0.6705,  0.0180, -0.2903, -0.0175,  0.5183,  0.2113,\n",
      "        -0.3722,  0.0689, -0.1745,  0.0098, -0.2392,  0.2353, -0.1356,  0.0952,\n",
      "        -0.1710, -0.0621, -0.0034, -0.2485,  0.0211, -0.1210,  0.3807, -0.4074,\n",
      "         0.4220, -0.1291,  0.5278, -0.1193, -0.5461, -0.6699,  0.5685,  0.1677,\n",
      "         0.0155,  0.1533,  0.3329, -0.3898,  0.1372, -0.1170,  0.0742, -0.4704,\n",
      "        -0.0079, -0.2003,  0.0586,  0.2609, -0.0598,  0.1954,  0.0789,  0.5840,\n",
      "         0.5099,  0.1693, -0.0938,  0.1875,  0.1775, -0.0441, -0.1858, -0.4465,\n",
      "         0.0365,  0.1505,  0.1631, -0.1888,  0.0225,  0.5314, -0.6127,  0.0158,\n",
      "        -0.1124,  0.0687, -0.2252,  0.1568,  0.0416,  0.5068, -0.3806, -0.0710,\n",
      "        -0.0117,  0.5701, -0.4224,  0.6236,  0.5432, -0.3216,  0.4151, -0.2057,\n",
      "         0.1804, -0.5501, -0.3718, -0.1889, -0.2619,  0.4057, -0.1134,  0.1692,\n",
      "        -0.4098, -0.0696, -0.1371, -0.1676,  0.2717, -0.1471, -0.3292, -0.4865,\n",
      "         0.0284,  0.0422, -0.5454, -0.4684, -0.4620,  0.5431, -0.3229,  0.0355,\n",
      "         0.1716,  0.0489,  0.8739, -0.4186, -0.2776,  0.6758,  0.3512,  0.0014,\n",
      "        -0.2272, -0.0243, -0.0658,  0.0449, -0.1673, -0.1374, -0.1672, -0.3809,\n",
      "        -0.1310, -0.2220,  0.1925, -0.2907,  0.2818, -0.1090, -0.4018,  0.0197,\n",
      "        -0.1767,  0.4713,  0.1471,  0.1538, -0.0028,  0.5351,  0.3487,  0.0911,\n",
      "         0.2864,  0.0294, -0.0975, -0.1253, -0.0213, -0.1764,  0.0012,  0.4468,\n",
      "         0.3909, -0.3225,  0.5577,  0.6751,  0.7113,  0.7906,  0.4549,  0.4133,\n",
      "        -0.0159, -0.5835, -0.0555, -0.1761,  0.0508, -0.8489,  0.0030,  0.2411,\n",
      "         0.0978,  0.0802, -0.1434,  0.3644,  0.0578,  0.3257,  0.4353,  0.1473,\n",
      "         0.2950, -0.7139,  0.7908,  0.6005,  0.0135, -0.0021,  0.5074,  0.3702,\n",
      "         0.2370,  0.0810, -0.0464,  0.1595,  0.3753, -0.2278, -0.0334,  0.4802,\n",
      "        -0.2601])\n",
      "predictors\n",
      "tensor([[-0.4889, -0.1231,  0.5302,  0.1241,  0.8752,  0.9881,  0.8573,  0.7099,\n",
      "         -0.0432, -0.8653, -0.6120,  0.6663, -0.3887, -0.1434, -0.6599,  0.1765,\n",
      "          0.9397, -0.1712,  0.8558, -0.9065,  0.4046, -0.2326, -0.0171,  0.8481,\n",
      "         -0.4142, -0.7036,  0.2108, -0.5153, -0.9037,  0.8960,  0.2310,  0.0950,\n",
      "          0.1682, -0.7300, -0.1210,  0.7924,  0.7782,  0.8909, -0.7367, -0.9224,\n",
      "          0.9477,  0.5790,  0.0492, -0.0961, -0.0742,  0.2147, -0.3217, -0.3222,\n",
      "          0.4568,  0.8632,  0.8195,  0.6905,  0.8230,  0.6865,  0.9461, -0.8283,\n",
      "         -0.2488, -0.3945, -0.9095,  0.3931,  0.9320, -0.4034,  0.7951,  0.5293,\n",
      "          0.5282,  0.8714, -0.5516,  0.1978,  0.2565, -0.3815,  0.9357,  0.2338,\n",
      "         -0.5142,  0.0509,  0.0491,  0.5674, -0.4599, -0.0862, -0.4967,  0.1982,\n",
      "          0.4354, -0.1806, -0.4395, -0.6025, -0.1505,  0.4456, -0.6942, -0.4962,\n",
      "         -0.9012,  0.0836, -0.8576,  0.3406, -0.0758,  0.3882,  0.3583,  0.3372,\n",
      "         -0.0412,  0.6068, -0.3648, -0.0416,  0.2082,  0.3270, -0.1545,  0.4032,\n",
      "         -0.9523,  0.5758,  0.7967, -0.5421, -0.6323, -0.8027,  0.5935, -0.8062,\n",
      "         -0.9946,  0.9068,  0.4923, -0.4775, -0.3937, -0.8279,  0.0418,  0.1001,\n",
      "         -0.4401, -0.4765,  0.1427,  0.6392,  0.1401, -0.9859, -0.5333,  0.5571,\n",
      "         -0.2270,  0.9856, -0.0162,  0.3215,  0.8442, -0.2510,  0.6543, -0.3771,\n",
      "         -0.0786,  0.7620, -0.6238,  0.8993, -0.0917,  0.3365, -0.8704,  0.9357,\n",
      "          0.6784, -0.6265,  0.6440, -0.7466,  0.7679,  0.6404, -0.1419,  0.8581,\n",
      "          0.2084,  0.9017,  0.9488,  0.3641, -0.8249,  0.3274, -0.6316, -0.6767,\n",
      "          0.5998, -0.5784,  0.5803, -0.2933, -0.7302,  0.5877,  0.3960,  0.8547,\n",
      "          0.6694,  0.1743,  0.6654,  0.0797,  0.7545, -0.5316, -0.7716,  0.5926,\n",
      "         -0.3730,  0.5048,  0.0042,  0.4628,  0.2980,  0.0318, -0.7936, -0.8031,\n",
      "         -0.6706, -0.7607,  0.3484, -0.0831, -0.8083,  0.3501,  0.0151, -0.6912,\n",
      "         -0.8792,  0.3844,  0.0376, -0.1107, -0.4343, -0.9395, -0.0695, -0.8579,\n",
      "         -0.0503, -0.2410, -0.0167, -0.4518, -0.2970, -0.7995, -0.6924,  0.9041,\n",
      "          0.6740,  0.7199,  0.0315, -0.7939,  0.6758,  0.3425,  0.9291,  0.9480,\n",
      "         -0.9955, -0.7629, -0.5374, -0.8204,  0.2579, -0.3424, -0.6369, -0.3578,\n",
      "         -0.7382],\n",
      "        [-0.9223, -0.9787,  0.9729, -0.5032,  0.3110,  0.4208,  0.1115, -0.4237,\n",
      "         -0.1939, -0.4320, -0.3457, -0.5326,  0.3431,  0.2925, -0.7136,  0.5097,\n",
      "          0.8500, -0.8627,  0.4904, -0.2776, -0.6341,  0.0260,  0.1508,  0.3573,\n",
      "          0.1484,  0.2707,  0.9688,  0.3933, -0.3288, -0.4443, -0.0228,  0.4299,\n",
      "          0.1451,  0.7030,  0.0559,  0.0277,  0.0028, -0.2385, -0.2297, -0.0933,\n",
      "         -0.2858,  0.2187,  0.6290, -0.5406, -0.0399,  0.6078, -0.0539, -0.8767,\n",
      "          0.6548, -0.6919,  0.4919,  0.8903, -0.9181, -0.7058, -0.0545, -0.0964,\n",
      "          0.5552,  0.6659,  0.8821, -0.3893, -0.4944,  0.5307, -0.9866,  0.8076,\n",
      "         -0.9760,  0.1745, -0.9499, -0.2105,  0.0779,  0.6486, -0.2817,  0.4163,\n",
      "          0.3791,  0.6081, -0.1031,  0.4343,  0.4790,  0.0672, -0.1459, -0.4246,\n",
      "         -0.9203,  0.2975, -0.4641, -0.3714,  0.5971, -0.3736, -0.5102,  0.6103,\n",
      "          0.1243, -0.9662,  0.7238,  0.6345, -0.7597,  0.7194,  0.2290,  0.7560,\n",
      "          0.6315,  0.3454, -0.4156, -0.1203, -0.8148,  0.0013,  0.8819,  0.2050,\n",
      "          0.9496, -0.8263,  0.2675, -0.3092, -0.9642, -0.7123, -0.4762,  0.2167,\n",
      "         -0.7403, -0.4894,  0.3832, -0.0799, -0.7553, -0.8355,  0.4866, -0.1755,\n",
      "         -0.3822,  0.8668,  0.6996, -0.8324, -0.0673, -0.9514, -0.3215,  0.3066,\n",
      "         -0.2169,  0.5979,  0.7929,  0.0245, -0.5608, -0.1609, -0.7733,  0.3984,\n",
      "          0.6320, -0.5598,  0.4842, -0.6150, -0.1582, -0.2901,  0.2480, -0.8275,\n",
      "         -0.8495,  0.0011, -0.2934,  0.5172,  0.2026, -0.8205,  0.5511,  0.4384,\n",
      "         -0.3104,  0.0730, -0.7559, -0.9717,  0.4661, -0.8021,  0.2521,  0.0181,\n",
      "          0.0993,  0.3240,  0.9766, -0.8624, -0.8093,  0.4385, -0.6692, -0.7414,\n",
      "         -0.8168, -0.9092,  0.2316,  0.7638, -0.5685, -0.4001,  0.6077, -0.7016,\n",
      "         -0.1941,  0.9753,  0.8592, -0.3946,  0.5830, -0.5479,  0.1743,  0.1547,\n",
      "          0.7074, -0.3746, -0.2984, -0.8166, -0.0233, -0.6724,  0.8831, -0.3938,\n",
      "          0.6352, -0.8798, -0.8975,  0.4449,  0.5013, -0.7014,  0.5651,  0.7419,\n",
      "          0.4929,  0.8625, -0.1025, -0.3371,  0.3393, -0.1302,  0.8152, -0.1968,\n",
      "         -0.9715,  0.6047,  0.4185,  0.6865,  0.9743, -0.8600,  0.5318, -0.8757,\n",
      "         -0.3201, -0.5033,  0.2735,  0.3962, -0.0673,  0.2672,  0.1577, -0.0990,\n",
      "          0.8143],\n",
      "        [ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "          1.0000]])\n",
      "accidents\n",
      "tensor([11.,  6.,  1.,  1.,  1.,  1.,  1.,  0.,  2.,  6.,  2.,  1.,  2.,  1.,\n",
      "         3.,  2.,  1.,  2.,  2.,  0.,  3.,  3.,  2.,  1.,  0.,  0.,  0.,  2.,\n",
      "         5.,  4.,  4.,  1.,  3.,  0.,  1.,  1.,  1.,  7.,  1.,  4.,  2.,  0.,\n",
      "         1.,  5.,  3.,  1.,  1.,  8.,  0.,  4.,  0.,  0.,  3.,  5.,  4.,  2.,\n",
      "         0.,  1.,  1.,  1.,  5.,  0., 11.,  1.,  6.,  2., 11.,  0.,  2.,  1.,\n",
      "         4.,  2.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  4.,  7.,  3.,  2.,  5.,\n",
      "         1.,  3.,  3.,  3.,  2.,  5.,  0.,  1.,  5.,  1.,  1.,  0.,  2.,  1.,\n",
      "         8.,  2.,  6.,  2.,  0.,  2.,  0.,  5.,  1.,  3.,  6., 14.,  2.,  2.,\n",
      "         8.,  4.,  1.,  8., 11.,  5.,  0.,  1.,  3.,  0.,  0.,  5.,  2., 15.,\n",
      "         3.,  0.,  2.,  2.,  0.,  2.,  2.,  2.,  6.,  0.,  0.,  2.,  0.,  3.,\n",
      "         2.,  3.,  2.,  6., 10.,  1.,  3.,  1.,  1.,  6.,  2.,  3.,  2.,  2.,\n",
      "         6.,  7.,  0.,  3.,  4.,  2.,  2.,  2.,  0.,  4.,  7.,  0.,  2.,  4.,\n",
      "        10., 13.,  1.,  1.,  5.,  4.,  1.,  2.,  4.,  1.,  0.,  5.,  0.,  3.,\n",
      "         2.,  4.,  0.,  1.,  3., 16.,  8.,  7.,  0.,  8.,  4.,  2.,  7.,  1.,\n",
      "         1.,  8.,  0.,  2.,  1.,  2.,  1.,  1.,  1.,  3.,  2.,  4.,  7.,  0.,\n",
      "         4.,  1.,  1.,  2.,  2.,  4.,  3.,  4.,  2.,  3.,  8.,  0.,  1.,  4.,\n",
      "         1.])\n"
     ]
    }
   ],
   "source": [
    "for key in params.keys(): \n",
    "    print(key)\n",
    "    print(params[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will implement the same model but I will be using the sparse version. Ideally, I will be able to get the same values as I did before but in a simpler way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 20\n",
    "cols = 20\n",
    "W = torch.tensor(utils.make_grid_adjacency_matrix(rows, cols), dtype=torch.float)\n",
    "W_sparse = torch.tensor(utils.make_sparse_representation_matrix(rows,cols))\n",
    "D_sparse = torch.sum(W,1, dtype=torch.float)\n",
    "D_invsq = torch.diag(1/torch.sqrt(D_sparse))\n",
    "D = torch.diag(torch.sum(W, 1))\n",
    "B = D_invsq @ W @ D_invsq\n",
    "eigenvalues, _ = torch.eig(B)\n",
    "eigen = eigenvalues[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_model(accidents,predictors):\n",
    "    n = rows * cols\n",
    "    \n",
    "    beta_dist = dist.Normal(torch.zeros(num_predictors + 1), var_beta)\n",
    "    betas = pyro.sample('betas',beta_dist)\n",
    "    \n",
    "    # Spatial correlation\n",
    "    alpha = pyro.sample('alpha', dist.Uniform(0.8,1))\n",
    "    tau = pyro.sample('tau', dist.Gamma(2,2))\n",
    "\n",
    "    phi_dist = utils.FastCar(alpha, tau, n, eigen, D_sparse, W_sparse)\n",
    "    phi = pyro.sample('phi', phi_dist)\n",
    "    \n",
    "    with pyro.plate('gen_data_plate', rows * cols): \n",
    "        noise = pyro.sample('noise', dist.Normal(0,noise_var))\n",
    "            \n",
    "    log_theta =  predictors @ betas + noise + phi\n",
    "    theta = torch.exp(log_theta)\n",
    "    pyro.sample('accidents', dist.Poisson(theta), obs = accidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 7000/7000 [3:14:39,  1.67s/it, step size=3.98e-08, acc. prob=0.719]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(fast_model, jit_compile=True, ignore_jit_warnings=True)\n",
    "mcmc = MCMC(nuts_kernel, num_samples = 6000, warmup_steps = 1000)\n",
    "mcmc.run(params['accidents'], params['predictors'].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: betas\n",
      "       mean       std        5%       25%       50%       75%       95%\n",
      "0 -0.727254  0.000004 -0.727257 -0.727256 -0.727255 -0.727254 -0.727243\n",
      "1  1.303648  0.000005  1.303642  1.303643  1.303646  1.303652  1.303655\n",
      "2 -0.648657  0.000003 -0.648660 -0.648659 -0.648658 -0.648657 -0.648650 \n",
      "\n",
      "site: alpha\n",
      "       mean           std        5%       25%       50%       75%       95%\n",
      "0  0.845388  1.551817e-07  0.845388  0.845388  0.845388  0.845388  0.845388 \n",
      "\n",
      "site: tau\n",
      "            mean            std            5%           25%            50%  \\\n",
      "0  232500.421875  173358.015625  11650.692871  66903.462891  212120.835938   \n",
      "\n",
      "             75%           95%  \n",
      "0  384647.515625  522658.24375   \n",
      "\n",
      "site: phi\n",
      "        mean       std        5%       25%       50%       75%       95%\n",
      "0   0.578108  0.000004  0.578099  0.578105  0.578109  0.578110  0.578111\n",
      "1  -0.081452  0.000003 -0.081455 -0.081453 -0.081452 -0.081450 -0.081448\n",
      "2   1.664188  0.000003  1.664181  1.664187  1.664190  1.664191  1.664191\n",
      "3   0.455112  0.000004  0.455105  0.455109  0.455114  0.455115  0.455117\n",
      "4  -1.755796  0.000005 -1.755800 -1.755799 -1.755798 -1.755795 -1.755785\n",
      "..       ...       ...       ...       ...       ...       ...       ...\n",
      "59  1.998921  0.000011  1.998896  1.998921  1.998926  1.998929  1.998929\n",
      "60 -0.331636  0.000003 -0.331640 -0.331637 -0.331636 -0.331635 -0.331633\n",
      "61 -1.842821  0.000004 -1.842828 -1.842824 -1.842821 -1.842818 -1.842817\n",
      "62  0.273013  0.000006  0.272999  0.273013  0.273015  0.273016  0.273017\n",
      "63 -0.946350  0.000005 -0.946355 -0.946354 -0.946352 -0.946349 -0.946340\n",
      "\n",
      "[64 rows x 7 columns] \n",
      "\n",
      "site: noise\n",
      "        mean       std        5%       25%       50%       75%       95%\n",
      "0   0.879691  0.000003  0.879689  0.879689  0.879690  0.879692  0.879698\n",
      "1  -0.284849  0.000002 -0.284851 -0.284851 -0.284850 -0.284848 -0.284844\n",
      "2  -0.601708  0.000008 -0.601731 -0.601707 -0.601705 -0.601704 -0.601703\n",
      "3  -1.549062  0.000001 -1.549064 -1.549062 -1.549062 -1.549061 -1.549061\n",
      "4  -1.353603  0.000004 -1.353611 -1.353604 -1.353603 -1.353602 -1.353597\n",
      "..       ...       ...       ...       ...       ...       ...       ...\n",
      "59 -1.750160  0.000004 -1.750167 -1.750162 -1.750159 -1.750157 -1.750156\n",
      "60  1.520730  0.000006  1.520717  1.520731  1.520733  1.520734  1.520735\n",
      "61  0.749696  0.000002  0.749690  0.749696  0.749696  0.749697  0.749697\n",
      "62 -0.151197  0.000002 -0.151201 -0.151197 -0.151197 -0.151196 -0.151194\n",
      "63 -1.179494  0.000001 -1.179495 -1.179495 -1.179494 -1.179493 -1.179490\n",
      "\n",
      "[64 rows x 7 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}\n",
    "\n",
    "for site, values in summary(hmc_samples).items():\n",
    "    print(\"site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
